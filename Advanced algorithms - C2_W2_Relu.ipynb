{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniPizarro4/Advanced-algorithms/blob/main/Advanced%20algorithms%20-%20C2_W2_Relu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrREkWAr8APH"
      },
      "source": [
        "# Optional Lab - ReLU activation"
      ],
      "id": "vrREkWAr8APH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BYpkfwG8API"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "plt.style.use('./deeplearning.mplstyle')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU\n",
        "from tensorflow.keras.activations import linear, relu, sigmoid\n",
        "%matplotlib widget\n",
        "from matplotlib.widgets import Slider\n",
        "from lab_utils_common import dlc\n",
        "from autils import plt_act_trio\n",
        "from lab_utils_relu import *\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n"
      ],
      "id": "6BYpkfwG8API"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKfhJzNj8APJ"
      },
      "source": [
        "<a name=\"2\"></a>\n",
        "## 2 - ReLU Activation\n",
        "This week, a new activation was introduced, the Rectified Linear Unit (ReLU).\n",
        "$$ a = max(0,z) \\quad\\quad\\text {# ReLU function} $$"
      ],
      "id": "sKfhJzNj8APJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "b0e09e3746204e77addfed0c91a09619"
          ]
        },
        "id": "WArlEb_t8APK",
        "outputId": "c6b29fdd-b3f6-436b-bdf2-2dc4db841f3f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0e09e3746204e77addfed0c91a09619",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt_act_trio()"
      ],
      "id": "WArlEb_t8APK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUMTQZO38APM"
      },
      "source": [
        "### Why Non-Linear Activations?  \n",
        "<img align=\"left\" src=\"./images/C2_W2_ReLU_Graph.png\"     style=\" width:250px; padding: 10px 20px; \" > The function shown is composed of linear pieces (piecewise linear). The slope is consistent during the linear portion and then changes abruptly at transition points. At transition points, a new linear function is added which, when added to the existing function, will produce the new slope. The new function is added at transition point but does not contribute to the output prior to that point. The non-linear activation function is responsible for disabling the input prior to and sometimes after the transition points. The following exercise provides a more tangible example."
      ],
      "id": "DUMTQZO38APM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9cbc8bea819144f59c1cd6cc21785173"
          ]
        },
        "id": "PZmKo8wO8APM",
        "outputId": "fa55d499-80c3-47be-ec4e-e641c8ab33a3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cbc8bea819144f59c1cd6cc21785173",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "_ = plt_relu_ex()"
      ],
      "id": "PZmKo8wO8APM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUMb4Qqq8APN"
      },
      "outputs": [],
      "source": [],
      "id": "mUMb4Qqq8APN"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}